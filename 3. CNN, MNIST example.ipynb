{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eight-jumping",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognition Using a Convolutional Network\n",
    "\n",
    "Based on PyTorch example at https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)\n",
    "\n",
    "<small>(https://commons.wikimedia.org/wiki/File:MnistExamples.png)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import random, datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "download_loc = '/tmp/'\n",
    "\n",
    "# The global mean and std deviation for the MNIST dataset\n",
    "# We'll use these to normalize the data\n",
    "mnist_mean = 0.1307\n",
    "mnist_std = 0.3081\n",
    "transformation = \\\n",
    "    torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((mnist_mean,), (mnist_std,))])\n",
    "\n",
    "# Load MNIST training and testing datasets\n",
    "train = torch.utils.data.DataLoader(torchvision.datasets.MNIST(download_loc, train=True, download=True, transform=transformation), batch_size=batch_size, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(torchvision.datasets.MNIST(download_loc, train=False, download=True, transform=transformation), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-equilibrium",
   "metadata": {},
   "source": [
    "The samples are greyscale $28 \\times 28$ images.  With the one greyscale channel, each image is a $1 \\times 28 \\times 28$ tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, digits = next(iter(train))\n",
    "plt.imshow(1 - torch.squeeze(samples[0]), cmap='gray')\n",
    "print(digits[0].item())\n",
    "print(samples[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-musician",
   "metadata": {},
   "source": [
    "We'll define the neural network and some helper modules here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few helper modules\n",
    "debug = True\n",
    "\n",
    "# If the debug global is enabled, this will print the shape of any input given\n",
    "class ShapeDebugger(torch.nn.Module):\n",
    "    def __init__(self, label):\n",
    "        super(ShapeDebugger, self).__init__()\n",
    "        self.label = label\n",
    "        \n",
    "    def forward(self, x):\n",
    "        global debug\n",
    "        if debug:\n",
    "            print(f'{self.label} ({x.shape})')\n",
    "        return x\n",
    "\n",
    "# Reshapes input to a given size\n",
    "class Reshaper(torch.nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super(Reshaper, self).__init__()\n",
    "        self.shape = shape\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.reshape(self.shape)\n",
    "\n",
    "# The convolutional network itself\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layers = torch.nn.Sequential(\n",
    "            ShapeDebugger('Input\\t\\t\\t'),\n",
    "            torch.nn.Conv2d(1,  10, kernel_size=5), \n",
    "            torch.nn.MaxPool2d(2), \n",
    "            torch.nn.ReLU(), \n",
    "            ShapeDebugger('1st Conv\\t\\t'),\n",
    "            torch.nn.Conv2d(10, 20, kernel_size=5), \n",
    "            torch.nn.Dropout2d(), \n",
    "            torch.nn.MaxPool2d(2), \n",
    "            torch.nn.ReLU(), \n",
    "            ShapeDebugger('2nd Conv\\t\\t'),\n",
    "            Reshaper((-1, 320)),\n",
    "            ShapeDebugger('Flattening\\t\\t'),\n",
    "            torch.nn.Linear(320, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            ShapeDebugger('1st fully-connected\\t'),\n",
    "            torch.nn.Dropout(),\n",
    "            torch.nn.Linear(100, 10),\n",
    "            torch.nn.LogSoftmax(dim=1),\n",
    "            ShapeDebugger('2nd fully-connected\\t'),\n",
    "        )\n",
    "\n",
    "    def forward(self, samples):\n",
    "        # Forward propagation\n",
    "        return self.layers(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-atmosphere",
   "metadata": {},
   "source": [
    "We can see how the shapes change through the forward propagation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()\n",
    "debug = True\n",
    "cnn.forward(samples)\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(cnn.parameters(), lr=0.01)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "loss_fn = torch.nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-sponsorship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_ds(ds):\n",
    "    full_loss = 0\n",
    "    for samples, values in ds:\n",
    "        with torch.no_grad(): # we don't need the gradient here! this speeds up execution\n",
    "            predicted = cnn(samples)\n",
    "            loss = loss_fn(predicted, values)\n",
    "            full_loss += loss.item()\n",
    "    return full_loss / len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-intake",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "train_loss.append(eval_ds(train))\n",
    "test_loss.append(eval_ds(test))\n",
    "print('epoch',0,train_loss[0])\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for samples, values in train:\n",
    "        opt.zero_grad()\n",
    "        predicted = cnn(samples)\n",
    "        loss = loss_fn(predicted, values)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    train_loss.append(eval_ds(train))\n",
    "    test_loss.append(eval_ds(test))\n",
    "    print('epoch',i+1,train_loss[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-andorra",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(test_loss, label='Testing Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    with torch.no_grad():\n",
    "        out = cnn(image.unsqueeze(0).unsqueeze(0)).numpy()\n",
    "        return np.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-pricing",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, digits = next(iter(train))\n",
    "img = torch.squeeze(samples[0])\n",
    "plt.imshow(1 - img, cmap='gray')\n",
    "print('Prediction', predict(img), 'True', digits[0].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
